# -*- coding: utf-8 -*-
"""Harris_coner_detector.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-jn1tD4R4CHntLX5IjALWPfTQI0hRoHZ
"""

import numpy as np
import cv2
import math
from google.colab.patches import cv2_imshow
from scipy.ndimage import convolve
from skimage.feature import corner_harris, corner_peaks
from scipy.ndimage import gaussian_filter
import matplotlib.pyplot as plt
from scipy import ndimage, datasets
from skimage.metrics import structural_similarity as compare_ssim
from Harris_Response import *
from Non_maximum_Suppression import *
from Get_coordinates import *
from Comparation_models import *
from Draw_lines import *

#rotated and scaled image
ori_img = cv2.imread(r'original_img.jpg')
gray_ori_img = cv2.cvtColor(ori_img, cv2.COLOR_BGR2GRAY)
R_gray_ori_img = my_cornerHarris(gray_ori_img, blockSize=3, ksize=3, k=0.05)
R_gray_ori_img = local_non_maximal_suppression(R_gray_ori_img)

# Mark corner points on image
#harris_response_2 = cv2.dilate(harris_response_2, None)
ori_img[R_gray_ori_img > 0.01 * R_gray_ori_img.max()] = (0, 0, 255)


res_rot_img = cv2.imread(r'rescaled_and_rotated_img.jpg')
gray_res_rot_img = cv2.cvtColor(res_rot_img, cv2.COLOR_BGR2GRAY)
R_gray_res_rot_img = my_cornerHarris(gray_res_rot_img, blockSize=3, ksize=3, k=0.05)
R_gray_res_rot_img = local_non_maximal_suppression(R_gray_res_rot_img)

# Mark corner points on image
#harris_response_2 = cv2.dilate(harris_response_2, None)
res_rot_img[R_gray_res_rot_img > 0.01 * R_gray_res_rot_img.max()] = (0, 0, 255)

# get coordinates
xy_gray_ori_img, val_gray_ori_img = get_max_corners(R_gray_ori_img)
xy_gray_res_rot_img, val_gray_res_rot_img = get_max_corners(R_gray_res_rot_img)

# Use Comparation model (SSIM, NCC, SSD)
ori_vs_res_and_rot = NCC(gray_ori_img, gray_res_rot_img, xy_gray_ori_img, xy_gray_res_rot_img, 17)

# Match
match_points = np.concatenate((ori_img, res_rot_img), axis=1)
gray_match_points = cv2.cvtColor(match_points, cv2.COLOR_BGR2GRAY)

#draw lines
#DRAW(match_images, test, 100)

#Showw result
cv2_imshow(DRAW(match_points, ori_vs_res_and_rot, 200))

#ori img vs complex img
books = cv2.imread(r'objects for detecting.jpg')
gray_books = cv2.cvtColor(books, cv2.COLOR_BGR2GRAY)
R_gray_books = my_cornerHarris(gray_books, blockSize=3, ksize=3, k=0.05)
R_gray_books = local_non_maximal_suppression(R_gray_books)

# Mark corner points on image

#harris_response_2 = cv2.dilate(harris_response_2, None)
books[R_gray_books > 0.01 * R_gray_books.max()] = (0, 0, 255)

# get coordinates
xy_gray_books, val_gray_books = get_max_corners(R_gray_books)

# Use Comparation model (SSIM, NCC, SSD)
ori_books = NCC(gray_ori_img, gray_books, xy_gray_ori_img, xy_gray_books, 17)

# Match
matches = np.concatenate((ori_img, books), axis=1)
gray_matches = cv2.cvtColor(matches, cv2.COLOR_BGR2GRAY)

# Draw lines
#DRAW(matches, test, 100)

# Show result
cv2_imshow(DRAW(matches, ori_books, 200))